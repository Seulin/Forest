{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tokenize\n",
    "import naming as nm\n",
    "import suji as sj\n",
    "import preference as pf\n",
    "import seulin as sn\n",
    "from crawling import getText, getOneText\n",
    "import io\n",
    "from time import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Feature:\n",
    "    __slots__ = ['name', 'users']\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "        users_link = 'http://114.71.103.80/new_db.php?q=select+*+from+users%0D%0Alimit+200%0D%0A%0D%0A'\n",
    "        self.users = getText(users_link, '1')\n",
    "\n",
    "    def make_df(feature_func):\n",
    "        def code_link(user):\n",
    "            before = 'http://114.71.103.80/new_db.php?q=select+*+from+code_submission+c%2C+%28select+id%2C+max%28regtime%29+a+from+code_submission+where+id+%3D'\n",
    "            after = '+group+by+p_no%29+d+where+c.id+%3D+d.id+and+d.a+%3D+c.regtime+'\n",
    "            return before + user + after\n",
    "        pass \n",
    "    \n",
    "    def cleaning(self):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "class NumberFeature(Feature):\n",
    "    pass\n",
    "\n",
    "class ListFeature(Feature):\n",
    "    pass\n",
    "\n",
    "f = Feature('hi')\n",
    "f.problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_row', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "users_link = 'http://114.71.103.80/new_db.php?q=select+*+from+users%0D%0Alimit+200%0D%0A%0D%0A'\n",
    "def code_link(user):\n",
    "    before = 'http://114.71.103.80/new_db.php?q=select+*+from+code_submission+c%2C+%28select+id%2C+max%28regtime%29+a+from+code_submission+where+id+%3D'\n",
    "    after = '+group+by+p_no%29+d+where+c.id+%3D+d.id+and+d.a+%3D+c.regtime+'\n",
    "    return before + user + after\n",
    "\n",
    "\n",
    "users = getText(users_link, '1')\n",
    "total_num_p = 78\n",
    "     \n",
    "\n",
    "def make_feature_df(feature_func, users, total_num_p = total_num_p):\n",
    "    df = pd.DataFrame(columns=users,index=range(1,total_num_p + 1))\n",
    "    start = time()\n",
    "    for user in users:\n",
    "        num_p = getText(code_link(user),  '2')\n",
    "        num_p = list(map(int, num_p))\n",
    "        problems = getText(code_link(user),  '4')\n",
    "        results=[]\n",
    "        for problem in problems:\n",
    "            stream = io.StringIO(problem)\n",
    "            tokens = tokenize.generate_tokens(stream.readline)\n",
    "            try:\n",
    "                results.append(feature_func(tokens))\n",
    "            except:\n",
    "                results.append(None) # None = error in code\n",
    "\n",
    "        result_i = 0\n",
    "        for i, v in enumerate(num_p):\n",
    "            df.loc[v][user] = results[i]\n",
    "        # NaN = problem isn't submitted\n",
    "    end = time()\n",
    "    print(f'Running time {end - start} sec')\n",
    "    return df\n",
    "\n",
    "def avg_cleaning(df): #suji\n",
    "    df.loc[:,'mean'] = df.mean(axis=1)\n",
    "    df = df.divide(df['mean'], axis = 0)\n",
    "    df = df.drop(['mean'], axis=1)\n",
    "    return df\n",
    "\n",
    "def self_cleaning(df): # yeram\n",
    "    num_p, num_u = df.shape\n",
    "    for i in range(1, num_p + 1):\n",
    "        for j in range(num_u):\n",
    "            lst=df.loc[i][j]\n",
    "            if type(lst) != list:\n",
    "                pass\n",
    "            else:\n",
    "                last_num=len(lst)-1\n",
    "                for k in range(len(lst)):\n",
    "                    if lst[last_num] != 0:\n",
    "                        lst[k]=lst[k]/lst[last_num]\n",
    "                del lst[last_num]\n",
    "                df.loc[i][j]=lst\n",
    "    return df\n",
    "\n",
    "\n",
    "def integrate(dfs, prob, user): #seulin\n",
    "    def check_shape(dfs): # check the shape of all dfs\n",
    "        shape = dfs[0].shape\n",
    "        for df in dfs:\n",
    "            assert(shape == df.shape)\n",
    "    check_shape(dfs)\n",
    "    res = []\n",
    "    for df in dfs:\n",
    "        feature = df.loc[prob][user]\n",
    "        if type(feature) == list:\n",
    "            res.extend(feature)\n",
    "        elif type(feature) in [int, float]:\n",
    "            res.append(feature)\n",
    "        else:\n",
    "            # NaN\n",
    "            pass\n",
    "    return res\n",
    "\n",
    "\n",
    "# get_distribution을 위한 함수, df에서 일부 레벨 별로 df를 추출함\n",
    "def get_problems_users(df, level, users):\n",
    "    return df.loc[(level-1)*10+1:level*10, users]\n",
    "\n",
    "def get_std_users(df, level, users):\n",
    "    stds = []\n",
    "    for u in users:\n",
    "        stds.append(get_std(level, u))\n",
    "    return pd.Series(stds, index=users)\n",
    "\n",
    "def get_std(df, level, user):\n",
    "    def get_problems(df, level, user):\n",
    "        #level 1 : 1~10번 문제, 2: 11~20번 문제\n",
    "        return df.loc[(level-1)*10+1:level*10][user]\n",
    "    series = get_problems(df, level, user)\n",
    "    if series.dtype in [int, float]:\n",
    "        return series.std()\n",
    "    elif series.dtype == object:\n",
    "        lst = series.tolist()\n",
    "        new = []\n",
    "        for prob in lst:\n",
    "            if type(prob) == list:\n",
    "                new.append(prob[0]) #나머지 항들도 같은 std 값임.\n",
    "        new = pd.Series(new)\n",
    "        return 1 - new.std()\n",
    "#         res = []\n",
    "#         for i in range(len(lst[0])): # length of each list\n",
    "#             new = pd.Series([prob[i] for prob in lst])\n",
    "#             res.append(new.std())\n",
    "#         return res\n",
    "# 유지도 : 개인별로 10개의 문제 기록을 보고 표준편차를 계산, 표준편차가 작으면 높은 가중치\n",
    "\n",
    "def calculate_plagiarism(origin, new, weights):\n",
    "    assert origin.size == new.size == weights.size\n",
    "    diff = origin - new\n",
    "    diff = diff.abs()\n",
    "    return diff*weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_update(res, new_data, ratio = 0.7):\n",
    "    if len(res) == 0:\n",
    "        # 판다스 카피 써라\n",
    "#     ////////////////////////////////////////////////\n",
    "#     왜 깊은 복사 안되지 df찍어보면 안다\n",
    "        res  =  copy.deepcopy(new_data)\n",
    "#     /////////////////////////////////////////////////\n",
    "        return copy.deepcopy(new_data)\n",
    "    \n",
    "    data_size = len(res)\n",
    "    arr_size = len(res[0])\n",
    "    \n",
    "    for i in range(data_size):\n",
    "        for j in range(arr_size):\n",
    "#             print(new_data[i])\n",
    "            try:\n",
    "                val = (1-ratio) * res[i][j] + ratio * new_data[i][j]\n",
    "                res[i][j] = round(val, 5)\n",
    "                \n",
    "            except:\n",
    "                if new_data[i] == None or np.isnan(new_data[i]):\n",
    "                    print(\"nan, none 발생\")\n",
    "                    break\n",
    "            \n",
    "    return res\n",
    "           \n",
    "    \n",
    "def total_update(data):\n",
    "    data_size = len(df)\n",
    "    res = []\n",
    "    \n",
    "    for i in range(1,data_size+1):\n",
    "        res = one_update(res, data.loc[i])\n",
    "        print(\"i=\",i)\n",
    "        print(res)\n",
    "        \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_distribution(data, n_clustering = 2):\n",
    "    \n",
    "    mean_df = data.mean()\n",
    "    np_mean_Df = mean_df.to_numpy().reshape(-1, 1)\n",
    "#     print(np_mean_Df)\n",
    "    \n",
    "    model = KMeans(n_clusters=n_clustering, init='k-means++', n_init=10, max_iter=300, tol=1e-4)\n",
    "    model.fit(np_mean_Df)\n",
    "\n",
    "    y_predict = model.labels_\n",
    "    n_y_predict = len(y_predict)\n",
    "\n",
    "    kmean_result = np.zeros(n_clustering) \n",
    "    \n",
    "    for i in range(n_y_predict):\n",
    "        kmean_result[y_predict[i]]+=1\n",
    "    kmean_result /= n_y_predict\n",
    "    \n",
    "    result = [kmean_result[pred_y] for pred_y in y_predict]\n",
    "    \n",
    "    \n",
    "    return pd.Series(result, index=list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "suji = [sj.Spared_Line, sj.Total_Line, sj.Annotation, sj.OpenParOpBl,\n",
    "         sj.CloseParOpBl, sj.EquOpBl, sj.MajOpBl, sj.CalOpBl, sj.ComOpBl,\n",
    "        sj.AssOpBl, sj.EtcOpBl]\n",
    "yeram = [nm.naming_class, nm.naming_function, nm.naming_variances,\n",
    "         nm.numbering, nm.len_variance]\n",
    "jihyuk = [pf.Quote_Preference, pf.InequalitySign_Preference,\n",
    "         pf.C_codingstyle_Preference, pf.String_Preference]\n",
    "seulin = [sn.func_Number, sn.funcParam_Number, sn.func_Return,\n",
    "          sn.func_Length, sn.tree_height, sn.nested_if, sn.nested_for]\n",
    "\n",
    "# feature 27개\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time 530.3547825813293 sec\n"
     ]
    }
   ],
   "source": [
    "# 정제한 df들 만들기\n",
    "\n",
    "# for func in [sj. ~~~~] 함수들 자기 전에 돌리고 자자.\n",
    "df1 = make_feature_df(sj.Annotation, users)\n",
    "df1 = self_cleaning(df1)\n",
    "df1.to_pickle(\"./dfs/Annotation.pkl\")\n",
    "\n",
    "df2 = make_feature_df(sj.OpenParOpBl, users)\n",
    "df2 = self_cleaning(df2)\n",
    "df2.to_pickle(\"./dfs/OpenParOpBl.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 저장한 df 불러오기\n",
    "df1 = pd.read_pickle(\"./dfs/Annotation.pkl\")\n",
    "df2 = pd.read_pickle(\"./dfs/OpenParOpBl.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    19900287  201411023  201411085  201411130  201411153  201511020  \\\n",
      "1   0.700000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
      "2  -0.033333  -1.230769  -1.230769        NaN  -1.230769  -1.230769   \n",
      "3  -0.250000   1.000000   0.500000   0.500000   0.666667  -0.250000   \n",
      "4   0.555556   0.000000   1.000000   1.000000   0.666667   0.333333   \n",
      "5   0.111111   0.875000   0.800000   0.818182   0.500000   0.400000   \n",
      "..       ...        ...        ...        ...        ...        ...   \n",
      "74 -0.088235        NaN  -0.088235        NaN        NaN  -0.088235   \n",
      "75       NaN        NaN  -0.627119        NaN        NaN  -0.627119   \n",
      "76 -0.254237        NaN  -0.928571  -1.260870  -1.291667        NaN   \n",
      "77       NaN        NaN        NaN        NaN   0.647059        NaN   \n",
      "78 -6.096774        NaN  -8.133333  -2.738462  -4.619048        NaN   \n",
      "\n",
      "    201511057  201511080  201511153  201611074  ... 201911179  201911180  \\\n",
      "1    1.000000   1.000000   1.000000   1.000000  ...  1.000000   1.000000   \n",
      "2         NaN        NaN  -1.230769        NaN  ... -1.230769  -1.230769   \n",
      "3    0.500000   0.500000   1.000000   1.000000  ...  0.250000   0.833333   \n",
      "4    0.000000   1.000000   1.000000   1.000000  ...  1.000000   1.000000   \n",
      "5    0.500000   1.000000   0.750000   1.000000  ...  0.875000   1.000000   \n",
      "..        ...        ...        ...        ...  ...       ...        ...   \n",
      "74  -0.088235        NaN  -0.088235        NaN  ... -0.088235        NaN   \n",
      "75  -0.627119        NaN  -0.627119        NaN  ... -0.627119        NaN   \n",
      "76  -1.625000        NaN  -1.375000  -1.375000  ...       NaN        NaN   \n",
      "77        NaN   0.511628        NaN        NaN  ...       NaN        NaN   \n",
      "78  -6.375000  -1.414698  -3.803922  -2.949721  ...       NaN  -7.756410   \n",
      "\n",
      "    201911182  201911183  201911185  201911186  201911187  201911188  \\\n",
      "1    1.000000   1.000000   1.000000   1.000000   0.541667   1.000000   \n",
      "2         NaN  -0.611111  -1.230769   0.250000  -1.230769  -1.230769   \n",
      "3   -0.750000   1.000000   0.250000  -0.250000   0.750000   0.333333   \n",
      "4    1.000000   1.000000  -0.500000   0.666667   1.000000   0.666667   \n",
      "5    0.000000   1.000000   0.100000   0.222222   0.666667   0.000000   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "74        NaN  -0.088235  -0.088235  -0.088235        NaN  -0.088235   \n",
      "75        NaN  -0.627119  -0.627119  -0.627119        NaN        NaN   \n",
      "76  -0.928571  -1.250000  -0.857143  -1.291667  -0.928571  -1.160000   \n",
      "77  -0.166667        NaN        NaN        NaN   0.230769        NaN   \n",
      "78  -4.068493  -7.000000        NaN  -2.462500  -5.798077  -3.140541   \n",
      "\n",
      "    201911189 201911190  \n",
      "1    1.000000  1.000000  \n",
      "2   -1.230769 -1.230769  \n",
      "3   -0.250000 -0.500000  \n",
      "4    0.500000  0.500000  \n",
      "5    0.125000  0.153846  \n",
      "..        ...       ...  \n",
      "74  -0.088235 -0.088235  \n",
      "75  -0.627119       NaN  \n",
      "76  -1.375000 -1.285714  \n",
      "77        NaN  0.111111  \n",
      "78  -6.047170 -3.112745  \n",
      "\n",
      "[78 rows x 200 columns]\n",
      "    19900287  201411023  201411085  201411130  201411153  201511020  \\\n",
      "1   0.000000        0.0   0.000000   0.000000   0.000000   0.000000   \n",
      "2   0.066667        0.0   0.000000        NaN   0.000000   0.000000   \n",
      "3   0.000000        0.0   0.000000   0.000000   0.000000   0.000000   \n",
      "4   0.111111        0.0   0.000000   0.000000   0.000000   0.000000   \n",
      "5   0.000000        0.0   0.000000   0.000000   0.000000   0.000000   \n",
      "..       ...        ...        ...        ...        ...        ...   \n",
      "74  0.029412        NaN   0.029412        NaN        NaN   0.029412   \n",
      "75       NaN        NaN   0.186441        NaN        NaN   0.186441   \n",
      "76  0.084746        NaN   0.142857   0.086957   0.083333        NaN   \n",
      "77       NaN        NaN        NaN        NaN   0.058824        NaN   \n",
      "78  0.086022        NaN   0.040000   0.215385   0.031746        NaN   \n",
      "\n",
      "    201511057  201511080  201511153  201611074  ... 201911179  201911180  \\\n",
      "1    0.000000   0.000000   0.000000   0.000000  ...  0.000000   0.000000   \n",
      "2         NaN        NaN   0.000000        NaN  ...  0.000000   0.000000   \n",
      "3    0.000000   0.000000   0.000000   0.000000  ...  0.000000   0.000000   \n",
      "4    0.200000   0.000000   0.000000   0.000000  ...  0.000000   0.000000   \n",
      "5    0.000000   0.000000   0.000000   0.000000  ...  0.000000   0.000000   \n",
      "..        ...        ...        ...        ...  ...       ...        ...   \n",
      "74   0.029412        NaN   0.029412        NaN  ...  0.029412        NaN   \n",
      "75   0.186441        NaN   0.186441        NaN  ...  0.186441        NaN   \n",
      "76   0.083333        NaN   0.083333   0.083333  ...       NaN        NaN   \n",
      "77        NaN   0.000000        NaN        NaN  ...       NaN        NaN   \n",
      "78   0.052083   0.049869   0.039216   0.016760  ...       NaN   0.038462   \n",
      "\n",
      "    201911182  201911183  201911185  201911186  201911187  201911188  \\\n",
      "1    0.000000   0.000000   0.000000   0.000000   0.083333   0.000000   \n",
      "2         NaN   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "3    0.500000   0.000000   0.000000   0.000000   0.250000   0.000000   \n",
      "4    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "5    0.285714   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "74        NaN   0.029412   0.029412   0.029412        NaN   0.029412   \n",
      "75        NaN   0.186441   0.186441   0.186441        NaN        NaN   \n",
      "76   0.142857   0.166667   0.142857   0.083333   0.142857   0.080000   \n",
      "77   0.055556        NaN        NaN        NaN   0.000000        NaN   \n",
      "78   0.075342   0.034884        NaN   0.050000   0.153846   0.027027   \n",
      "\n",
      "    201911189 201911190  \n",
      "1    0.000000  0.000000  \n",
      "2    0.000000  0.000000  \n",
      "3    0.000000  0.000000  \n",
      "4    0.000000  0.000000  \n",
      "5    0.000000  0.153846  \n",
      "..        ...       ...  \n",
      "74   0.029412  0.029412  \n",
      "75   0.186441       NaN  \n",
      "76   0.083333  0.214286  \n",
      "77        NaN  0.111111  \n",
      "78   0.037736  0.171569  \n",
      "\n",
      "[78 rows x 200 columns]\n",
      "    19900287  201411023  201411085  201411130  201411153  201511020  \\\n",
      "1   0.300000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "2   0.966667   2.230769   2.230769        NaN   2.230769   2.230769   \n",
      "3   1.250000   0.000000   0.500000   0.500000   0.333333   1.250000   \n",
      "4   0.333333   1.000000   0.000000   0.000000   0.333333   0.666667   \n",
      "5   0.888889   0.125000   0.200000   0.181818   0.500000   0.600000   \n",
      "..       ...        ...        ...        ...        ...        ...   \n",
      "74  1.058824        NaN   1.058824        NaN        NaN   1.058824   \n",
      "75       NaN        NaN   1.440678        NaN        NaN   1.440678   \n",
      "76  1.169492        NaN   1.785714   2.173913   2.208333        NaN   \n",
      "77       NaN        NaN        NaN        NaN   0.294118        NaN   \n",
      "78  7.010753        NaN   9.053333   3.503846   5.563492        NaN   \n",
      "\n",
      "    201511057  201511080  201511153  201611074  ... 201911179  201911180  \\\n",
      "1    0.000000   0.000000   0.000000   0.000000  ...  0.000000   0.000000   \n",
      "2         NaN        NaN   2.230769        NaN  ...  2.230769   2.230769   \n",
      "3    0.500000   0.500000   0.000000   0.000000  ...  0.750000   0.166667   \n",
      "4    0.800000   0.000000   0.000000   0.000000  ...  0.000000   0.000000   \n",
      "5    0.500000   0.000000   0.250000   0.000000  ...  0.125000   0.000000   \n",
      "..        ...        ...        ...        ...  ...       ...        ...   \n",
      "74   1.058824        NaN   1.058824        NaN  ...  1.058824        NaN   \n",
      "75   1.440678        NaN   1.440678        NaN  ...  1.440678        NaN   \n",
      "76   2.541667        NaN   2.291667   2.291667  ...       NaN        NaN   \n",
      "77        NaN   0.488372        NaN        NaN  ...       NaN        NaN   \n",
      "78   7.291667   2.356955   4.745098   3.916201  ...       NaN   8.679487   \n",
      "\n",
      "    201911182  201911183  201911185  201911186  201911187  201911188  \\\n",
      "1    0.000000   0.000000   0.000000   0.000000   0.375000   0.000000   \n",
      "2         NaN   1.611111   2.230769   0.750000   2.230769   2.230769   \n",
      "3    1.250000   0.000000   0.750000   1.250000   0.000000   0.666667   \n",
      "4    0.000000   0.000000   1.500000   0.333333   0.000000   0.333333   \n",
      "5    0.714286   0.000000   0.900000   0.777778   0.333333   1.000000   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "74        NaN   1.058824   1.058824   1.058824        NaN   1.058824   \n",
      "75        NaN   1.440678   1.440678   1.440678        NaN        NaN   \n",
      "76   1.785714   2.083333   1.714286   2.208333   1.785714   2.080000   \n",
      "77   1.111111        NaN        NaN        NaN   0.769231        NaN   \n",
      "78   4.972603   7.930233        NaN   3.393750   6.644231   4.097297   \n",
      "\n",
      "    201911189 201911190  \n",
      "1    0.000000  0.000000  \n",
      "2    2.230769  2.230769  \n",
      "3    1.250000  1.500000  \n",
      "4    0.500000  0.500000  \n",
      "5    0.875000  0.692308  \n",
      "..        ...       ...  \n",
      "74   1.058824  1.058824  \n",
      "75   1.440678       NaN  \n",
      "76   2.291667  2.071429  \n",
      "77        NaN  0.777778  \n",
      "78   6.981132  3.926471  \n",
      "\n",
      "[78 rows x 200 columns]\n",
      "    19900287  201411023  201411085  201411130  201411153  201511020  \\\n",
      "1        0.0        0.0       0.00   0.000000    0.00000        0.0   \n",
      "2        0.0        0.0       0.00        NaN    0.00000        0.0   \n",
      "3        0.0        0.0       0.00   0.000000    0.00000        0.0   \n",
      "4        0.0        0.0       0.00   0.000000    0.00000        0.0   \n",
      "5        0.0        0.0       0.00   0.000000    0.00000        0.0   \n",
      "..       ...        ...        ...        ...        ...        ...   \n",
      "74       0.0        NaN       0.00        NaN        NaN        0.0   \n",
      "75       NaN        NaN       0.00        NaN        NaN        0.0   \n",
      "76       0.0        NaN       0.00   0.000000    0.00000        NaN   \n",
      "77       NaN        NaN        NaN        NaN    0.00000        NaN   \n",
      "78       0.0        NaN       0.04   0.019231    0.02381        NaN   \n",
      "\n",
      "    201511057  201511080  201511153  201611074  ... 201911179  201911180  \\\n",
      "1     0.00000   0.000000   0.000000    0.00000  ...       0.0   0.000000   \n",
      "2         NaN        NaN   0.000000        NaN  ...       0.0   0.000000   \n",
      "3     0.00000   0.000000   0.000000    0.00000  ...       0.0   0.000000   \n",
      "4     0.00000   0.000000   0.000000    0.00000  ...       0.0   0.000000   \n",
      "5     0.00000   0.000000   0.000000    0.00000  ...       0.0   0.000000   \n",
      "..        ...        ...        ...        ...  ...       ...        ...   \n",
      "74    0.00000        NaN   0.000000        NaN  ...       0.0        NaN   \n",
      "75    0.00000        NaN   0.000000        NaN  ...       0.0        NaN   \n",
      "76    0.00000        NaN   0.000000    0.00000  ...       NaN        NaN   \n",
      "77        NaN   0.000000        NaN        NaN  ...       NaN        NaN   \n",
      "78    0.03125   0.007874   0.019608    0.01676  ...       NaN   0.038462   \n",
      "\n",
      "    201911182  201911183  201911185  201911186  201911187  201911188  \\\n",
      "1    0.000000   0.000000        0.0    0.00000        0.0   0.000000   \n",
      "2         NaN   0.000000        0.0    0.00000        0.0   0.000000   \n",
      "3    0.000000   0.000000        0.0    0.00000        0.0   0.000000   \n",
      "4    0.000000   0.000000        0.0    0.00000        0.0   0.000000   \n",
      "5    0.000000   0.000000        0.0    0.00000        0.0   0.000000   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "74        NaN   0.000000        0.0    0.00000        NaN   0.000000   \n",
      "75        NaN   0.000000        0.0    0.00000        NaN        NaN   \n",
      "76   0.000000   0.000000        0.0    0.00000        0.0   0.000000   \n",
      "77   0.000000        NaN        NaN        NaN        0.0        NaN   \n",
      "78   0.020548   0.034884        NaN    0.01875        0.0   0.016216   \n",
      "\n",
      "    201911189 201911190  \n",
      "1    0.000000  0.000000  \n",
      "2    0.000000  0.000000  \n",
      "3    0.000000  0.000000  \n",
      "4    0.000000  0.000000  \n",
      "5    0.000000  0.000000  \n",
      "..        ...       ...  \n",
      "74   0.000000  0.000000  \n",
      "75   0.000000       NaN  \n",
      "76   0.000000  0.000000  \n",
      "77        NaN  0.000000  \n",
      "78   0.028302  0.014706  \n",
      "\n",
      "[78 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "#df2를 element df로 쪼개는 함수가 필요함.\n",
    "def seperate_df(df):\n",
    "    assert df.iloc[:, 0].dtype == object\n",
    "    \n",
    "    def get_element(i):\n",
    "        def help(lst):\n",
    "            if type(lst) == list:\n",
    "                return lst[i]\n",
    "        return help\n",
    "    \n",
    "    for j in range(len(df.iloc[0, 0])): # lst len\n",
    "        res = df.applymap(get_element(j))\n",
    "        print(res)\n",
    "    \n",
    "seperate_df(df2)\n",
    "\n",
    "\n",
    "def get_feature_weight(distribution, std):\n",
    "    return distribution.multiply(std)\n",
    "\n",
    "# user별로\n",
    "def iterate(user):\n",
    "    get_std()\n",
    "    distri = get_distribution\n",
    "    수지함수(distri)\n",
    "    \n",
    "    c = get_feature_weight(distribution, std):\n",
    "    a = original\n",
    "    b = new problem\n",
    "    \n",
    "    update(a, b, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4f726bc21a0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# kmeans으로 학생들 사이의 분산 구하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_problems_users\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 표편으로 유지도 구하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f559b0dfb105>\u001b[0m in \u001b[0;36mget_distribution\u001b[1;34m(data, n_clustering)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_clustering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-means++'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_mean_Df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_x\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[1;32m--> 859\u001b[1;33m                         order=order, copy=self.copy_x)\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# feature 가중치 구하기\n",
    "level = 1\n",
    "\n",
    "# kmeans으로 학생들 사이의 분산 구하기\n",
    "temp = get_problems_users(df1, 1, users)\n",
    "print(get_distribution(temp))\n",
    "\n",
    "# 표편으로 유지도 구하기\n",
    "temp = get_std(df1. level, users)\n",
    "print(temp)\n",
    "####################################\n",
    "\n",
    "# kmeans으로 학생들 사이의 분산 구하기\n",
    "temp = get_problems_users(df2, 1, users)\n",
    "print(get_distribution(temp))\n",
    "\n",
    "# 표편으로 유지도 구하기\n",
    "temp = get_std(df2. level, users)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 1.0, 1.153846153846154]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로 들어오는 문제의 코딩 스타일을 정의\n",
    "integrate([df1, df2], 10, \"201411023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and read\n",
    "df.to_pickle(\"./dfs/feature_df.pkl\")\n",
    "df_data = pd.read_pickle(\"./dfs/feature_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
